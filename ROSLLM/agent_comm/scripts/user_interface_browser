#!/usr/bin/env python3
import inspect
import os
import threading
import warnings
from pathlib import Path

import gradio as gr
import rospy
import whisper
from rosllm_srvs.srv import GetUserInput, GetUserInputResponse

# ─────────────── shared flags / data ────────────────
latest_prompt   = ""
user_input      = ""
prompt_evt      = threading.Event()
user_ready_evt  = threading.Event()

# ─────────────── Whisper model (loaded once) ───────
warnings.filterwarnings("ignore", category=UserWarning,
                        message="FP16 is not supported on CPU")
whisper_model = whisper.load_model("base", device="cpu")

# ─────────────── ROS service handler ───────────────

def srv_callback(req):
    global latest_prompt, user_input
    latest_prompt = req.prompt
    user_input = ""
    user_ready_evt.clear()
    prompt_evt.set()
    rospy.loginfo(f"[UI] Prompt received: {latest_prompt}")

    user_ready_evt.wait()
    return GetUserInputResponse(user_input)


def ros_service_thread():
    rospy.Service("get_user_input", GetUserInput, srv_callback)
    rospy.loginfo("Gradio‑input service ready.")
    rospy.spin()

# ─────────────── helpers ───────────────────────────

def get_audio_path(val):
    """Return a local filepath from the Gradio Audio value (str or dict)."""
    if val is None:
        return None
    if isinstance(val, str):
        return val
    if isinstance(val, dict):
        return val.get("path") or val.get("name")
    return None

# ─────────────── GUI callbacks ──────────────────────

def poll_for_prompt(history):
    if prompt_evt.is_set():
        history = history + [[latest_prompt, None]]
        prompt_evt.clear()
        return history, history
    return gr.update(), history


def on_send(msg, history):
    if not history or history[-1][1] is not None:
        return history, ""
    history[-1][1] = msg
    global user_input
    user_input = msg
    user_ready_evt.set()
    return history, ""


def on_audio_upload(audio_val, history):
    path = get_audio_path(audio_val)
    if not path or not Path(path).is_file():
        rospy.logwarn("No audio recorded or file not found.")
        return gr.update(), None, history

    try:
        result = whisper_model.transcribe(path)
        transcript = result["text"].strip()
    except Exception as e:
        rospy.logwarn(f"Whisper failed: {e}")
        transcript = "[transcription‑error]"

    if not history or history[-1][1] is not None:
        return history, None, history

    history[-1][1] = transcript
    global user_input
    user_input = transcript
    user_ready_evt.set()
    return history, None, history


def quit_app():
    rospy.loginfo("Shutting down interface…")
    os._exit(0)

# ─────────────── Utility: make Audio component ────

def make_audio_component():
    sig = inspect.signature(gr.Audio.__init__)
    common_kwargs = dict(type="filepath", format="wav",
                         label="🎙️ Voice reply (click to record)")
    if "sources" in sig.parameters:      # Gradio 4.x
        return gr.Audio(sources=["microphone"], **common_kwargs)
    elif "source" in sig.parameters:     # Gradio 3.x
        return gr.Audio(source="microphone", **common_kwargs)
    raise RuntimeError("Unsupported gr.Audio signature; please update Gradio.")

# ─────────────── main ──────────────────────────────

def main():
    rospy.init_node("gradio_input_server")
    threading.Thread(target=ros_service_thread, daemon=True).start()

    with gr.Blocks(title="RobotChat") as demo:
        gr.Markdown("## Robot Chat Interface")

        chatbot   = gr.Chatbot(height=320)
        textbox   = gr.Textbox(label="Your response",
                               placeholder="Type and press Send / Enter…")
        audio_rec = make_audio_component()
        send_btn  = gr.Button("Send")
        quit_btn  = gr.Button("Quit Interface", variant="stop")
        history_state = gr.State([])

        demo.load(poll_for_prompt,
                  inputs=history_state,
                  outputs=[chatbot, history_state],
                  every=0.5,
                  show_progress=False)

        send_btn.click(on_send,
                       inputs=[textbox, history_state],
                       outputs=[chatbot, textbox])

        textbox.submit(on_send,
                       inputs=[textbox, history_state],
                       outputs=[chatbot, textbox])

        audio_rec.change(on_audio_upload,
                         inputs=[audio_rec, history_state],
                         outputs=[chatbot, audio_rec, history_state])

        quit_btn.click(quit_app)

    demo.launch()

if __name__ == "__main__":
    main()
