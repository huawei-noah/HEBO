defaults:
  - /llm: ???
  - memory: default
  - prompt_builder: default
  - _self_
  - /llm@embedding:

_target_: src.agent.agents.LLMAgent
name: unnamed
version: v0.1

on_init_flow: null
post_action_flow:
  _target_: agent.commands.SequentialFlow
  sequence:
    - _target_: agent.commands.SaveTrajectory
on_episode_start_flow: null
on_episode_end_flow: null
pre_action_flow: ???

embedding: null

# Override LLM generation params (top_k not exposed by OpenAI):

# llm:
#   temperature: 1
#   top_p: 1

# As a guide (from https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api-a-few-tips-and-tricks-on-controlling-the-creativity-deterministic-output-of-prompt-responses/172683):
# Use Case	                 Temperature	 Top_p	 Description
# Code Generation	           0.2	         0.1	   Generates code that adheres to established patterns and conventions. Output is more deterministic and focused. Useful for generating syntactically correct code.
# Creative Writing	         0.7	         0.8	   Generates creative and diverse text for storytelling. Output is more exploratory and less constrained by patterns.
# Chatbot Responses	         0.5	         0.5	   Generates conversational responses that balance coherence and diversity. Output is more natural and engaging.
# Code Comment Generation	   0.3	         0.2	   Generates code comments that are more likely to be concise and relevant. Output is more deterministic and adheres to conventions.
# Data Analysis Scripting	   0.2	         0.1	   Generates data analysis scripts that are more likely to be correct and efficient. Output is more deterministic and focused.
# Exploratory Code Writing	 0.6	         0.7	   Generates code that explores alternative solutions and creative approaches. Output is less constrained by established patterns.
