{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":29841,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-tuner","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import mnist\n\nfrom kerastuner import RandomSearch\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import RMSprop\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom keras.datasets import mnist\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv('../input/digit-recognizer/train.csv')\nlabels = train.iloc[:,0].values.astype('int32')\n\nX_train = (train.iloc[:,1:].values).astype('float32')\nX_test = (pd.read_csv('../input/digit-recognizer/test.csv').values).astype('float32')\n\n#reshape into images\nX_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1,28,28,1)\n\n# one hot encoding\ny_train = tf.keras.utils.to_categorical(labels) \n\nprint(\"Check data\")\nprint(labels)\nprint(X_train[0].shape)\nprint(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Data from Keras MNIST\n(train_imagesRaw, train_labelsRaw), (test_imagesRaw, test_labelsRaw) = mnist.load_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshape into images\nX_train_keras = train_imagesRaw.reshape(-1,28,28,1)\nX_test_keras = test_imagesRaw.reshape(-1,28,28,1)\n\nprint(\"X_train_keras\",X_train_keras.shape)\nprint(\"X_test_keras\",X_test_keras.shape)\n\ntrain_labels_keras = tf.keras.utils.to_categorical(train_labelsRaw)\ntest_labels_keras = tf.keras.utils.to_categorical(test_labelsRaw)\nprint(\"train_labels_keras \",train_labels_keras.shape)\nprint(\"test_labels_keras \", test_labels_keras.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge datasets\n\ntrain_images = np.concatenate((X_train_keras,X_train,X_test_keras), axis=0)\nprint(\"new Concatenated train_images \", train_images.shape)\nprint(\"_\"*50)\n\ntrain_labels = np.concatenate((train_labels_keras,y_train,test_labels_keras), axis=0)\nprint(\"new Concatenated train_labels \", train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize an image\n\nfig = plt.figure()\nplt.imshow(X_train[6][:,:,0], cmap='gray', interpolation='none')\nplt.xticks([])\nplt.yticks([])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scale = np.max(train_images)\ntrain_images /= scale\nX_test /= scale\n\n#visualize scales\n\nprint(\"Max: {}\".format(scale))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we define the input and output layer sizes\ninput_size = X_train.shape\nn_logits = y_train.shape[1]\n\nprint(\"Input: {}\".format(input_size))\nprint(\"Output: {}\".format(n_logits))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(hp):\n    \"\"\"Function that build a TF model based on hyperparameters values.\n    Args:\n        hp (HyperParameter): hyperparameters values\n    Returns:\n        Model: Compiled model\n    \"\"\"\n    num_layers = hp.Int('num_layers', min_value=2, max_value=16, step=2)\n    \n    lr = hp.Choice('learning_rate', [1e-3, 5e-4])\n\n    inputs = layers.Input(shape=(28, 28, 1))\n    x = inputs\n\n    for idx in range(num_layers):\n        idx = str(idx)\n\n        filters = hp.Int('filters_' + idx, 32, 256, step=32, default=64)\n        x = layers.Conv2D(filters=filters, kernel_size=3, padding='same',\n                          activation='relu')(x)\n\n        # add a pooling layers if needed\n        if x.shape[1] >= 8:\n            pool_type = hp.Choice('pool_' + idx, values=['max', 'avg'])\n            if pool_type == 'max':\n                x = layers.MaxPooling2D(2)(x)\n            elif pool_type == 'avg':\n                x = layers.AveragePooling2D(2)(x)\n\n    # My dense layer\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(n_logits, activation='softmax')(x)\n              \n    # Build model\n    model = keras.Model(inputs, outputs)\n    model.compile(optimizer=Adam(lr),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=8,\n    executions_per_trial=3,\n    directory='my_dir',\n    project_name='mnist')\n\ntuner.search_space_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train, y_train,\n             epochs=30,\n             validation_data=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate predictions\npredictions_vector = model.predict(X_test, verbose=0)\npredictions = np.argmax(predictions_vector,axis=1)\n\npd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions}).to_csv(\"preds.csv\", index=False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}