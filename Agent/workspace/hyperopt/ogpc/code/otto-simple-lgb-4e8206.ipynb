{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4280,"databundleVersionId":860643,"sourceType":"competition"}],"dockerImageVersionId":29852,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\n# import optuna.integration.lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import log_loss\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/otto-group-product-classification-challenge/train.csv')\ntest = pd.read_csv('../input/otto-group-product-classification-challenge/test.csv')\nsample_submit = pd.read_csv('../input/otto-group-product-classification-challenge/sampleSubmission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace 'Class_1' ~ 'Class_9' to 0~8\ntrain['target'] = train['target'].str.replace('Class_', '')\ntrain['target'] = train['target'].astype(int) - 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"data = pd.concat([train, test])\ncols = [c for c in data.columns if c not in ['id', 'target']]\n\nfor col in cols:\n    dictionary=data[col].value_counts().to_dict()\n    data['count_'+col]=data[col].map(dictionary)\nfrom sklearn import preprocessing\n\ndata['max_val'] = data[cols].max(axis=1)\ndata['sum_val'] = data[cols].sum(axis=1)\ndata['non_zero'] = (data[cols] > 0).sum(axis=1)\ndata['count_one'] = (data[cols] == 1).sum(axis=1)\ndata['count_two'] = (data[cols] == 2).sum(axis=1)\ndata['count_three'] = (data[cols] == 3).sum(axis=1)\n\ntrain = data[~data['target'].isnull()].reset_index(drop=True)\ntest = data[data['target'].isnull()].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train setting\nNFOLDS = 5\nRANDOM_STATE = 871972\n\nexcluded_column = ['target', 'id']\ncols = [c for c in train.columns if c not in excluded_column]\n\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, \n                        random_state=RANDOM_STATE)\n\n# parameter calculated by LGBtuner\nparams = {\n    'metric':'multi_logloss','objective': 'multiclass',   'num_class': 9,   'verbosity': 1,\n    'feature_fraction': 0.4, 'num_leaves': 139, 'bagging_fraction': 0.8254401463359962, 'bagging_freq': 3,\n    'lambda_l1': 0.02563829140437355, 'lambda_l2': 9.594334397031103, 'min_child_samples': 100\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = np.zeros((len(test), 9))\noof = np.zeros((len(train), 9))\nscore = 0\nfeature_importance_df = pd.DataFrame()\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y = train['target'])):\n    print('Fold', fold_n)\n    X_train, X_valid = train.iloc[train_index], train.iloc[valid_index]\n    y_train, y_valid = X_train['target'].astype(int), X_valid['target'].astype(int)\n    \n    train_data = lgb.Dataset(X_train[cols], label=y_train)\n    valid_data = lgb.Dataset(X_valid[cols], label=y_valid)\n\n    lgb_model = lgb.train(params,train_data,num_boost_round=30000,\n                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 300)\n    \n    y_pred_valid = lgb_model.predict(X_valid[cols], num_iteration=lgb_model.best_iteration)\n    oof[valid_index] = y_pred_valid\n    score += log_loss(y_valid, y_pred_valid)\n    \n    y_pred_test += lgb_model.predict(test[cols], num_iteration=lgb_model.best_iteration)/NFOLDS\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = cols\n    fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_n + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\nprint('valid logloss average:', score/NFOLDS, log_loss(train['target'], oof))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\", as_index=False).mean().sort_values(by=\"importance\", ascending=False).head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.concat([sample_submit[['id']], pd.DataFrame(y_pred_test)], axis = 1)\nsubmit.columns = sample_submit.columns\nsubmit.to_csv('submit.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_name = ['lgb_' + str(i) for i in range(9)]\npd.DataFrame(oof, columns = column_name).to_csv('oof_lgb.csv', index=False)\npd.DataFrame(y_pred_test, columns = column_name).to_csv('submit_lgb.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}