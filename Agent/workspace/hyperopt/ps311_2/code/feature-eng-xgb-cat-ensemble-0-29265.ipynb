{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":47790,"databundleVersionId":5172264,"sourceType":"competition"},{"sourceId":4449018,"sourceType":"datasetVersion","datasetId":2605336}],"dockerImageVersionId":30446,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ðŸ›‘If you use this topic as a fork or to submit/ensemble the output, don't forget to **show support** !ðŸ›‘\n## If you don't understand some of the things I do, check out [this notebook](https://www.kaggle.com/code/janmpia/what-you-need-to-know-about-this-competition)","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import KFold, GroupKFold,StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import log_loss\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import scale\nfrom sklearn.calibration import CalibrationDisplay\nfrom itertools import combinations\nfrom itertools import permutations\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport optuna\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier\nimport joblib\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBRegressor\nimport xgboost as xgb\nfrom sklearn.metrics import log_loss\nsns.set(style=\"ticks\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-30T14:41:25.151826Z","iopub.execute_input":"2023-03-30T14:41:25.152188Z","iopub.status.idle":"2023-03-30T14:41:30.493113Z","shell.execute_reply.started":"2023-03-30T14:41:25.152156Z","shell.execute_reply":"2023-03-30T14:41:30.492078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_total = pd.read_csv(\"/kaggle/input/playground-series-s3e11/train.csv\")\ntest = pd.read_csv('/kaggle/input/playground-series-s3e11/test.csv')\noriginal = pd.read_csv('/kaggle/input/media-campaign-cost-prediction/train_dataset.csv')\nX_train,X_test,Y_train,Y_test = train_test_split(train_total.drop([\"cost\"],axis=1),train_total[\"cost\"],test_size=0.2,stratify=train_total[\"cost\"], random_state = 100)\ntrain = pd.merge(X_train,Y_train, on =X_train['id'])\nhold = pd.merge(X_test,Y_test, on =X_test['id'])\ntrain['id'] = range(0, len(train))\ndef empty_callback(env):\n    pass","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:30.495107Z","iopub.execute_input":"2023-03-30T14:41:30.495552Z","iopub.status.idle":"2023-03-30T14:41:32.433583Z","shell.execute_reply.started":"2023-03-30T14:41:30.495515Z","shell.execute_reply":"2023-03-30T14:41:32.432529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engeneering/selection","metadata":{}},{"cell_type":"code","source":"FEATS = [\"total_children\", \"num_children_at_home\", \"avg_cars_at home(approx).1\",\n         \"store_sqft\", \"coffee_bar\", \"video_store\", 'florist',\"prepared_food\"]\nINIT_FEATS =[\"total_children\", \"num_children_at_home\", \"avg_cars_at home(approx).1\",'unit_sales(in millions)','store_sales(in millions)','units_per_case',\n         \"store_sqft\", \"coffee_bar\", \"video_store\", 'florist',\"prepared_food\",'average_children','average_units','average_sales','gross_weight']\n\nCAT_FEATS = FEATS.copy()\navg_df = pd.DataFrame(index = train.store_sqft.unique())\navg_df['store_sqft'] = avg_df.index\n\navg_df_test = pd.DataFrame(index = test.store_sqft.unique())\navg_df_test['store_sqft'] = avg_df_test.index\n\navg_df_hold = pd.DataFrame(index = hold.store_sqft.unique())\navg_df_hold['store_sqft'] = avg_df_hold.index\n\n\navg_df_original = pd.DataFrame(index = original.store_sqft.unique())\navg_df_original['store_sqft'] = avg_df_original.index\n\nconcat_train_hold_test = pd.concat([train,hold,test],ignore_index=True)\nfor feature in INIT_FEATS:\n    if feature in ['units_per_case','store_sales(in millions)','total_children']:\n        avg_df[f'avg_{feature}'] = concat_train_hold_test.groupby('store_sqft')[feature].mean()\n        avg_df_test[f'avg_{feature}'] = concat_train_hold_test.groupby('store_sqft')[feature].mean()\n        avg_df_hold[f'avg_{feature}'] = concat_train_hold_test.groupby('store_sqft')[feature].mean()\n        avg_df_original[f'avg_{feature}'] = concat_train_hold_test.groupby('store_sqft')[feature].mean()\n        \n        CAT_FEATS.append(f'avg_{feature}')\n\ntrain = pd.merge(train, avg_df, on='store_sqft', how='left')\nhold = pd.merge(hold, avg_df_hold, on='store_sqft', how='left')\ntest = pd.merge(test, avg_df_test, on='store_sqft', how='left')\noriginal = pd.merge(original, avg_df_original, on='store_sqft', how='left')\navg_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.435263Z","iopub.execute_input":"2023-03-30T14:41:32.435636Z","iopub.status.idle":"2023-03-30T14:41:32.822389Z","shell.execute_reply.started":"2023-03-30T14:41:32.4356Z","shell.execute_reply":"2023-03-30T14:41:32.82124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATS","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.825464Z","iopub.execute_input":"2023-03-30T14:41:32.825849Z","iopub.status.idle":"2023-03-30T14:41:32.832137Z","shell.execute_reply.started":"2023-03-30T14:41:32.825812Z","shell.execute_reply":"2023-03-30T14:41:32.831061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CAT_FEATS","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.833808Z","iopub.execute_input":"2023-03-30T14:41:32.834554Z","iopub.status.idle":"2023-03-30T14:41:32.844941Z","shell.execute_reply.started":"2023-03-30T14:41:32.834491Z","shell.execute_reply":"2023-03-30T14:41:32.843942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[FEATS] = train[FEATS].round(2)\noriginal[FEATS] = original[FEATS].round(2)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.84697Z","iopub.execute_input":"2023-03-30T14:41:32.84762Z","iopub.status.idle":"2023-03-30T14:41:32.928735Z","shell.execute_reply.started":"2023-03-30T14:41:32.847584Z","shell.execute_reply":"2023-03-30T14:41:32.92769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.930363Z","iopub.execute_input":"2023-03-30T14:41:32.930764Z","iopub.status.idle":"2023-03-30T14:41:32.959817Z","shell.execute_reply.started":"2023-03-30T14:41:32.930725Z","shell.execute_reply":"2023-03-30T14:41:32.958734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_bins =5\ntrain['bins'] = pd.cut(train['cost'], bins=num_bins).astype('category')\nbins = train['bins'].unique()\nbin_map = {}\nfor i,bin in enumerate(bins):\n    bin_map[bin] = i\n    \ntrain['bins'] = train['bins'].map(bin_map)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.961405Z","iopub.execute_input":"2023-03-30T14:41:32.961784Z","iopub.status.idle":"2023-03-30T14:41:32.989631Z","shell.execute_reply.started":"2023-03-30T14:41:32.961748Z","shell.execute_reply":"2023-03-30T14:41:32.988671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"ALL_USERS = train.id.unique()\ngkf = GroupKFold(n_splits=5)\noof = pd.DataFrame(index=ALL_USERS)\n\n#hyperparams\ncat_params = {\n    'iterations': 10000,\n    'learning_rate': 0.07,\n    'depth': 11,\n    'l2_leaf_reg':8 ,\n    'random_strength':0.5,\n    'loss_function': 'RMSE',\n    'eval_metric': 'RMSE',\n    'task_type': 'GPU',\n    'border_count': 128,\n    'verbose': 1000,\n    'early_stopping_rounds': 100,\n    'use_best_model': True ,\n    'random_state': 42,\n    \n}\n\nxgb_params = {\n    'objective': 'reg:squarederror',\n    'tree_method': 'gpu_hist',\n    'eval_metric': 'rmse',\n    'seed': 42,\n    'n_estimators': 1000,\n    'learning_rate': 0.14774138317002128,\n    'early_stopping_rounds': 1000,\n    'max_depth': 11,\n    'subsample': 0.90,\n    'colsample_bytree': 0.90,\n\n    'alpha': 4,\n    'lambda': 5\n}\n\ntargets = np.log(train.cost+1)\nn_splits = 5\nkf = KFold(n_splits=5, shuffle=True, random_state=100)\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\nnum_trees_cat = []\nnum_trees_xgb = []\n\nfor i, (train_index, test_index) in enumerate(skf.split(X=train, y=train['bins'], groups=train.index)):\n    print(f'\\nFold {i+1}:')\n\n    train_x = train.iloc[train_index]\n    train_x = pd.concat([train_x,original])\n    train_gems = train_x.index.values\n    train_y = targets.loc[train_gems]\n\n    valid_x = train.iloc[test_index]\n    valid_gems = valid_x.index.values\n    valid_y = targets.loc[valid_gems]\n    \n    model_dict = {\n            'cat': [CatBoostRegressor(**cat_params),{\"eval_set\":[(valid_x[CAT_FEATS].astype('float32'), valid_y)],'plot':False},CAT_FEATS],\n            'xgb': [XGBRegressor(**xgb_params),{\"eval_set\":[(valid_x[FEATS].astype('float32'), valid_y)],\"verbose\":0},FEATS],\n         }\n    \n    all_models = model_dict.keys()\n    for model in all_models:\n        clf = model_dict[model][0]\n        clf.fit(train_x[model_dict[model][2]].astype('float32'), train_y, **model_dict[model][1])\n        \n        oof.loc[valid_gems, f'{model}_prediction'] = np.exp(clf.predict(valid_x[model_dict[model][2]].astype('float32')))-1\n        print(f'model {model} trained')\n        if model == 'cat':\n            num_trees_cat.append(clf.get_best_iteration())\n        if model == 'xgb':\n            num_trees_xgb.append(clf.best_ntree_limit)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:41:32.991242Z","iopub.execute_input":"2023-03-30T14:41:32.991606Z","iopub.status.idle":"2023-03-30T14:45:30.813651Z","shell.execute_reply.started":"2023-03-30T14:41:32.991569Z","shell.execute_reply":"2023-03-30T14:45:30.812585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stratified CV","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\nrmses = {}\ntargets = train.cost\nfor model in all_models:\n    rmses[f\"{model}_prediction\"] = mean_squared_log_error(targets,oof[f'{model}_prediction'], squared=False)\n    print(f'{model} = {rmses[f\"{model}_prediction\"]}')\n    \noof['prediction'] = 0\nrmse_inv_sum = 0\nfor model in all_models:\n    if model in ['xgb','lgb','cat']:\n        oof['prediction'] = oof['prediction'] + oof[f'{model}_prediction'] * (1/rmses[f'{model}_prediction'])\n        rmse_inv_sum += 1/rmses[f'{model}_prediction']\n    \n#print('xgb = 0.2930786590554832')\noof['prediction'] = oof['prediction'] / rmse_inv_sum\nprint(f'ensemble = {mean_squared_log_error(targets,oof[f\"prediction\"], squared=False)}')","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:45:30.81897Z","iopub.execute_input":"2023-03-30T14:45:30.819281Z","iopub.status.idle":"2023-03-30T14:45:30.87054Z","shell.execute_reply.started":"2023-03-30T14:45:30.819249Z","shell.execute_reply":"2023-03-30T14:45:30.868885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(17,8)) \nsns.histplot(data=oof, x=\"prediction\",bins = 100, ax=ax, kde = True)\nax2 = ax.twinx()\nsns.boxplot(data=oof, x=\"prediction\", ax=ax2,boxprops=dict(alpha=.7))\nax2.set(ylim=(-.5, 10))\nplt.suptitle('Cost countplot and Boxplot for my train predictions', fontsize=20)\nax.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:45:30.873627Z","iopub.execute_input":"2023-03-30T14:45:30.873943Z","iopub.status.idle":"2023-03-30T14:45:32.48187Z","shell.execute_reply.started":"2023-03-30T14:45:30.873908Z","shell.execute_reply":"2023-03-30T14:45:32.480834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hold","metadata":{}},{"cell_type":"code","source":"print(f\"CAT :{num_trees_cat}; mean : {np.array(num_trees_cat).mean()}\")\nprint(f\"XGB :{num_trees_xgb}; mean : {np.array(num_trees_xgb).mean()}\")\nprint()\nhold_num_trees_cat = int(np.array(num_trees_cat).mean()*1.25)\nhold_num_trees_xgb = int(np.array(num_trees_xgb).mean()*1.25)\n#cat model\ncat_params2 = cat_params.copy()\ncat_params2.pop('iterations')\ncat_params2.pop('early_stopping_rounds')\ncat_params2.pop('use_best_model')\nnew_params = {\n    'iterations': hold_num_trees_cat,\n}\n\nhold_cat = CatBoostRegressor(**cat_params2,**new_params)\nhold_cat.fit(train[CAT_FEATS].astype('float32'), np.log(train.cost+1),plot=False)\n\n\n#xgb model\nxgb_params2 = xgb_params.copy()\nxgb_params2.pop('early_stopping_rounds')\nxgb_params2['n_estimators'] = hold_num_trees_xgb\n\nhold_xgb = XGBRegressor(**xgb_params2)\nhold_xgb.fit(train[FEATS].astype('float32'), np.log(train.cost+1))\n\n#hold oof\nhold_pred = pd.DataFrame(index = hold.id)\n\nhold_pred['cat_predictions'] = np.exp(hold_cat.predict(hold[CAT_FEATS].astype('float32')))-1\nhold_pred['xgb_predictions'] = np.exp(hold_xgb.predict(hold[FEATS].astype('float32')))-1\nhold_pred['predictions'] = (hold_pred['xgb_predictions'] + hold_pred['cat_predictions']) /2\n\n#rmsles\nprint(f\"\\nhold cat prediction: {mean_squared_log_error(hold.cost,hold_pred['cat_predictions'], squared=False)}\")\nprint(f\"hold xgb prediction: {mean_squared_log_error(hold.cost,hold_pred['xgb_predictions'], squared=False)}\")\nprint(f\"\\nhold ensemble prediction: {mean_squared_log_error(hold.cost,hold_pred['predictions'], squared=False)}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:45:32.482891Z","iopub.execute_input":"2023-03-30T14:45:32.483236Z","iopub.status.idle":"2023-03-30T14:46:06.106509Z","shell.execute_reply.started":"2023-03-30T14:45:32.483202Z","shell.execute_reply":"2023-03-30T14:46:06.105527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hold_pred.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:46:06.110829Z","iopub.execute_input":"2023-03-30T14:46:06.113128Z","iopub.status.idle":"2023-03-30T14:46:06.129271Z","shell.execute_reply.started":"2023-03-30T14:46:06.113089Z","shell.execute_reply":"2023-03-30T14:46:06.128016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"new_params = {\n    'iterations': int(hold_num_trees_cat*1.25),\n}\n\nlast_train = pd.concat([train,hold,original], ignore_index=True)\n\ntest_cat = CatBoostRegressor(**cat_params2,**new_params)\n\nxgb_params3 = xgb_params2.copy()\nxgb_params3['n_estimators'] = int(xgb_params3['n_estimators']*1.25)\ntest_xgb = XGBRegressor(**xgb_params3)\n\ntest_xgb.fit(last_train[FEATS].astype('float32'), np.log(last_train.cost+1))\ntest_cat.fit(last_train[CAT_FEATS].astype('float32'), np.log(last_train.cost+1),plot=False)\n\nsubmission = pd.DataFrame(index = test.id)\nsubmission['id'] = submission.index\n\nsubmission['cost_xgb'] = np.exp(test_xgb.predict(test[FEATS].astype('float32')))-1\nsubmission['cost_cat'] = np.exp(test_cat.predict(test[CAT_FEATS].astype('float32')))-1\nsubmission['cost'] = (submission['cost_xgb'] + submission['cost_cat']) / 2","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:46:06.133337Z","iopub.execute_input":"2023-03-30T14:46:06.135552Z","iopub.status.idle":"2023-03-30T14:47:02.285508Z","shell.execute_reply.started":"2023-03-30T14:46:06.135516Z","shell.execute_reply":"2023-03-30T14:47:02.284443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:47:02.287029Z","iopub.execute_input":"2023-03-30T14:47:02.287404Z","iopub.status.idle":"2023-03-30T14:47:02.301681Z","shell.execute_reply.started":"2023-03-30T14:47:02.287367Z","shell.execute_reply":"2023-03-30T14:47:02.300287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[['id','cost']].to_csv('submission.csv', index= False)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T14:47:02.303422Z","iopub.execute_input":"2023-03-30T14:47:02.303865Z","iopub.status.idle":"2023-03-30T14:47:02.74577Z","shell.execute_reply.started":"2023-03-30T14:47:02.303825Z","shell.execute_reply":"2023-03-30T14:47:02.744708Z"},"trusted":true},"execution_count":null,"outputs":[]}]}