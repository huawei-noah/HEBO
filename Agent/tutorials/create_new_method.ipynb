{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a new method in Agent\n",
    "\n",
    "This notebook will take you through all the steps required to create an LLM prompting method from scratch, so that you can do the same for your custom methods. We will look at creating everything needed for the direct method. This method is already a part of the framework but we will recreate it from scratch so that you can follow the same steps for your own methods.\n",
    "\n",
    "Note: Please make sure you have first installed all dependencies of Agent, following the installation guide!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create prompt templates\n",
    "\n",
    "This is similar to the first step in creating a new task, since most tasks require their own definition of prompting methods to fit the environment. in this exmaple we create the direct method for the GSM8k task.\n",
    "\n",
    "Under `../src/agent/prompts/templates/gsm8k/` we will define the template .jinja files for any messages sent to the LLM according to our new method. \n",
    "\n",
    "All methods must end with an external action which is taken in the task environment. As such an `external_action.jinja` file must be defined in the appropriate task folder (or the `../src/agent/prompts/templates/default/external_action.jinja` can be extended). \n",
    "\n",
    "In fact, for the direct prompting method, onlt the external action template is necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_action = \"\"\"\n",
    "[[ SYSTEM ]]\n",
    "You are an expert mathematician. You are provided with mathematical questions that you have to answer.\n",
    "When asked for an answer, your response should use the following format:\n",
    "Answer: <answer>\n",
    "\n",
    "[[ USER ]]\n",
    "Question: {{memory.retrieve(memory.mem_keys.OBSERVATION})}}\n",
    "\n",
    "Now please answer the question.\n",
    "Answer in the format\n",
    "Answer: <answer>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../src/agent/prompts/templates/gsm8k/external_action.jinja\", \"w\") as file:\n",
    "    file.write(external_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we defined all the template content needed for the direct prompting emthod from scratch, but actually you can often use content from the `../src/agent/prompts/templates/default/` templates folder, and even task templates such as `../src/agent/prompts/templates/gsm8k/system_prompt.jinja`, which are not method-specific. Many methods will reuse a lot of the same prompt content, and as such we enable users to simply define the new elements that change, as seen in the \"Create a new task\" guide. Also note that while the direct prompting method only requires an external action template for prompting the LLM, methods which prompt the LLM multiple times will require at least one template per different call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a method configuration\n",
    "\n",
    "Create a new configuration file under `../configs/method/` which should define the method's Flow. See the documentation for more details on Flows and intrinsic functions. Here we use already existing flows and intrinsic functions to define the direct prompting method, composed of a single `SequentialFlow` with a single `Act` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = \"\"\"\n",
    "# @package _global_\n",
    "agent:\n",
    "  pre_action_flow:\n",
    "    _target_: agent.commands.SequentialFlow\n",
    "    sequence:\n",
    "      - _target_: agent.commands.Act\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../configs/method/direct_example.jinja\", \"w\") as file:\n",
    "    file.write(direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Running the method\n",
    "\n",
    "Assuming you are using an existing LLM configuration, say OpenChat-3.5, the method can be run for GSM8k as follows. The method argument must be the name of the config file defined in [Step 2](#step-2-create-a-method-configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! python ../src/agent/start.py task=gsm8k method=direct llm@agent.llm=hf/openchat_3.5 max_episodes=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up files\n",
    "\n",
    "Here we clean up the files created by this notebook to avoid cluttering the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"../src/agent/prompts/templates/gsm8k/external_action.jinja\")\n",
    "    os.remove(\"../configs/method/direct_example.jinja\")\n",
    "except OSError as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
