{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "We first must install all required packages necessary for agent to run. Packages here are managed by `poetry`. For ease of use, we convert the poetry lock to a `requirements.txt` file. We then `pip install` the packages within this file.\n",
    "\n",
    "Any errors are encountered during installation of any particular package can usually be resolved by manually pip installng that package individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry export --without-hashes --all-extras > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tasks require the installation of additional data or packages, run the cell below to install these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install build-essential cmake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a custom task\n",
    "\n",
    "Now let's go through how to integrate your own task and llm in the agent,\n",
    "in this case, we use deepseek-coder as the LLM and implement and a custom task in robotics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Specify task config\n",
    "We must first specify a config file for the task in the /confis/task/ directory. \n",
    "\n",
    "For example: /configs/task/example_task.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_task_yaml = '''\n",
    "# @package _global_\n",
    "agent:\n",
    "  main_flow: ???\n",
    "  prompt_builder:\n",
    "    template_paths:\n",
    "      - example_task\n",
    "      - default\n",
    "\n",
    "task:\n",
    "  _target_: agent.tasks.example_task.Example_task\n",
    "\n",
    "  name: example_task_test_env\n",
    "  description:\n",
    "  subtask: null\n",
    "  version: v0.1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement a custom task class \n",
    "Within /src/agent/tasks/ we define a new file titled example_task.py. We define a new Task class named Example_Task. In this new Task class instance, we can define new functions specific to our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "import subprocess\n",
    "from agent.tasks import ActionSpace\n",
    "from agent.tasks import DatasetCompleteException\n",
    "from agent.tasks import Task\n",
    "from rclpy.node import Node\n",
    "from std_srvs.srv import Empty\n",
    "from std_msgs.msg import String\n",
    "from r2pbi_commif.srv import CommandWithPath, CommandLookUpDist\n",
    "import rclpy\n",
    "import threading\n",
    "\n",
    "def extract_tree(text):\n",
    "    match = re.search(r'```(.*?)```', text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_text = match.group(1)\n",
    "        return extracted_text\n",
    "    else:\n",
    "        print(\"No text found between triple backticks.\")\n",
    "        return extracted_text\n",
    "\n",
    "class Example_Task(Task):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.observation_space = NotImplemented\n",
    "        self.action_space = ActionSpace.CONTINUOUS\n",
    "        self.args = kwargs\n",
    "        self.episode_counter = 0\n",
    "\n",
    "        # init ros node and start the environment\n",
    "        rclpy.init()\n",
    "        self.node = Node(\"sim_env_node\")\n",
    "        thread = threading.Thread(target=self.launch_env)\n",
    "        thread.start()\n",
    "\n",
    "        # define the client to access env\n",
    "        self.reset_client, self.start_video_client, self.end_video_client, self.dist_of_obj_client = self.start_clients()\n",
    "\n",
    "        # define gripper object to judge if final state is good \n",
    "        self.obj_on_gripper_ = ''\n",
    "        object_ongripper_subscriber = self.node.create_subscription(\n",
    "            String,\n",
    "            '/robot/object_on_gripper',\n",
    "            self.listener_callback,\n",
    "            10)\n",
    "        object_ongripper_subscriber\n",
    "\n",
    "\n",
    "    def reset(self, next_subtask: str | None = None):\n",
    "        self.done = False\n",
    "        \n",
    "        self.text_obs = 'pick up an red box.'\n",
    "\n",
    "    def get_observation(self):\n",
    "        return {\"text\": self.text_obs, \"_available_actions\": \"\"}\n",
    "\n",
    "\n",
    "    def is_complete(self):\n",
    "        return self.done\n",
    "    \n",
    "    def parse_method(self, raw_response: str):\n",
    "        try:\n",
    "            proposed_answer = extract_tree(raw_response)\n",
    "        except Exception as e:\n",
    "            proposed_answer = f\"{e}\"\n",
    "        return proposed_answer\n",
    "\n",
    "    def step(self, action):\n",
    "        package_name = 'btcpp_machine'\n",
    "        node_name = 'run_bt_client'\n",
    "        parameter_name = 'bt_xml'\n",
    "        self.done = True\n",
    "        try:\n",
    "            command = [\n",
    "            'ros2', 'run', package_name, node_name,\n",
    "            '--ros-args', '-p', f'{parameter_name}:={action}'\n",
    "            ]\n",
    "            self.node.get_logger().info(\"reset sim\")\n",
    "            future = self.reset_client.call_async(Empty.Request())\n",
    "            rclpy.spin_until_future_complete(self.node, future, timeout_sec=20.0)\n",
    "\n",
    "            self.node.get_logger().info(\"start test\")\n",
    "            # Run the command and capture output\n",
    "            process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=60)\n",
    "            self.text_obs = process.stderr\n",
    "\n",
    "            # calculate reward \n",
    "            self.node.get_logger().info(\"calculate reward.\")\n",
    "            reward = self.calculate_reward()\n",
    "        except Exception:\n",
    "            reward = self.calculate_reward()\n",
    "        return reward, self.done\n",
    "    \n",
    "    def launch_env(self):\n",
    "        package_name = 'r2pbi_env'\n",
    "        launch_name = 'v2prototype.launch.py'\n",
    "        command = [\n",
    "            'ros2', 'launch', package_name, launch_name\n",
    "        ]\n",
    "        while True:\n",
    "            print(\"start launch...\")\n",
    "            process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "            print(\"launch process dead, restart.....\")\n",
    "\n",
    "    def start_clients(self):\n",
    "        reset_client = self.node.create_client(Empty, '/simulation/reset_sim')\n",
    "        while not reset_client.wait_for_service(timeout_sec=1.0):\n",
    "                self.node.get_logger().info('Service not available, waiting again...')\n",
    "        start_video_client = self.node.create_client(CommandWithPath, '/simulation/record_video_start')\n",
    "        while not start_video_client.wait_for_service(timeout_sec=1.0):\n",
    "                self.node.get_logger().info('Service start_video not available, waiting again...')\n",
    "        end_video_client = self.node.create_client(CommandWithPath, '/simulation/record_video_end')\n",
    "        while not end_video_client.wait_for_service(timeout_sec=1.0):\n",
    "                self.node.get_logger().info('Service end_video not available, waiting again...')\n",
    "        dist_of_obj_client = self.node.create_client(CommandLookUpDist, '/robot/distance_to_object')\n",
    "        while not dist_of_obj_client.wait_for_service(timeout_sec=1.0):\n",
    "                self.node.get_logger().info('Service not available, waiting again...')\n",
    "        return reset_client, start_video_client, end_video_client, dist_of_obj_client\n",
    "    \n",
    "    def listener_callback(self, msg):\n",
    "        self.obj_on_gripper_ = msg.data\n",
    "    \n",
    "    def calculate_reward(self):\n",
    "        # check if the action is correct\n",
    "        reward = 0\n",
    "        self.node.get_logger().info(f\"after tree execution, object on gripper is {self.obj_on_gripper_}\")\n",
    "        if self.obj_on_gripper_ == \"red_box\":\n",
    "            reward += 10\n",
    "        \n",
    "        # calculate distance to target \n",
    "        future = self.dist_of_obj_client.call_async(CommandLookUpDist.Request(object = 'red_box'))\n",
    "        rclpy.spin_until_future_complete(self.node, future, timeout_sec=20.0)\n",
    "        reward -= future.result().distance.data *100.0\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define prompt template\n",
    "\n",
    "We now create a new directory to save custom prompt templates for our example task. Within /src/agent/prompts/example_task we create .jinja files to represent prompt templates. Below we define three prompts: \n",
    "*    system_prompt.jinja: a prompt to define the task to the LLM\n",
    " *   context_example.jinja: a prompt that serves to give the agent contextual information as to how the environment works, used to direct the agent to generate related content.\n",
    "  *  cot_prompt.jinja: used to get the agent to genrate a chain of thought and think step-by-step\n",
    "\n",
    "In this example, we want to generate a behaviour tree using an LLM., and structure prompts to represent this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "[[ SYSTEM ]]\n",
    "You are an agent that has to design a behaviour tree in xml format which follows BTCPP_format=\"4\" standard with available actions and conditions.\n",
    "You have to follow the instructions.\n",
    "* Make sure the behaviour tree is surround by ``` ```\n",
    "* Every round I will give you an observation and a list of available actions, objects and available places, you have to respond an action based on the state and task.\n",
    "* You only have access to the Nodes/Actions/Conditions provided, you can not create new ones, this is a strict requirement.\n",
    "* The behaviour tree must be in a xml format, follow BTCPP_format=\"4\" standard.\n",
    "* It may be the case that the task fails, you should include in the behaviour tree a case for recovering from potential issues.\n",
    "* You must open gripper before grasp, and do not open gripper once grasp.\n",
    "* You must navigate to find the object position.\n",
    "\n",
    "{%- if cot_type in [\"zero_shot_cot\", \"few_shot_cot\"] %}\n",
    "When asked for an action, you should think step by step, and then finish by providing an available action from the list.\n",
    "Your response should be in the following format:\n",
    "Thought: ...\n",
    "Action: <action>\n",
    "{%- else %}\n",
    "When asked for an action, your response should be an available action from the list, using the following format:\n",
    "Action: <action>\n",
    "{%- endif %}\n",
    "'''\n",
    "\n",
    "context_example = '''\n",
    "The available Nodes/Actions/Conditions/Objects/Places are presented below:\n",
    "\n",
    "Tree Nodes:\n",
    "{\n",
    "root: root node should in format <root BTCPP_format=\"4\">\n",
    "BehaviorTree: <BehaviorTree> must be next layer of root\n",
    "Sequence: A Sequence ticks all its children as long as they return SUCCESS. If any child returns FAILURE, the sequence is aborted.\n",
    "Fallback: If a child returns FAILURE, the fallback ticks the next child. If the last child returns FAILURE too, all the children are halted and the fallback returns FAILURE. If a child returns SUCCESS, it stops and returns SUCCESS. All the children are halted. \n",
    "Inverter: tick the child once and return SUCCESS if the child failed or FAILURE if the child succeeded.\n",
    "RetryUntilSuccessful: try number of times until subnode success\n",
    "<RetryUntilSuccessful num_attempts=\"<max_number_of_attempt>\">\n",
    "}\n",
    "'''\n",
    "\n",
    "cot_prompt = '''\n",
    "Now please think step by step, and then finish by providing behaviour tree that will help you complete the task.\n",
    "Note: You can have multiple thoughts, but Only generate one behaviour tree.\n",
    "Answer in the format\n",
    "Thought: ...\n",
    "Tree: ```<behaviour tree>```\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define LLM server info\n",
    "We must define an LLM backend for the agent to use. Within /configs/llm we create a file example_task_llm.yaml. Within this file, we specify the LLM and server IP that we want the agent to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_task_llm = '''\n",
    "_target_: agent.llms.llm.OpenAIBackend\n",
    "_partial_: true\n",
    "server_ip: http://10.227.91.35:8000/v1\n",
    "model_id: deepseek-coder-6.7b-instruct\n",
    "api_key: EMPTY\n",
    "max_response_tokens: 3000\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: We test our custom example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/agent/start.py task=example_task method=fs-cot llm@_agents.0.llm=example_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
